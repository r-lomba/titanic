{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sopravviverai alla sciagura del Titanic? Un Classificatore Binario basato su Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operazioni preliminari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo Jupyter Notebook ci permetterà di completare in ogni sua parte tutte le fasi richieste per partecipare alla Kaggle Competition \"Titanic - Machine Learning from Disaster\", descritta ampiamente nell'articolo. Il progetto si suddivide logicamente nelle seguenti Sezioni, che varranno affrontate una ad una:\n",
    "\n",
    "- Operazioni preliminari, caricamento Librerie, Setup dell'Ambiente\n",
    "- Data Preparation del Dataset di TRAINING fornito da Kaggle a corredo\n",
    "- Costruzione del Modello di Rete Neurale che verrà usato per effettuare le Predizioni sul Dataset di TEST fornito da Kaggle, e privo della cosiddetta \"Class Label\" (ovvero dell'informazione che ci dice se il Passeggero in esame è sopravvissuto al disastro oppure no). Tali Predizioni che sono l'oggetto vero e proprio della Competition\n",
    "- Training del Midello utilizzando il Dataset preparato nelle fasi precedenti\n",
    "- Inferenza dei risultati oggetto della Competition, usando il Modello addestrato nelle fasi precedenti\n",
    "- Generazione di un file CSV in formato adatto ad essere uploadato e valutato sul sito della Competition\n",
    "- Valutazione della propria prestazione in classifica generale!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importiamo le librerie necessarie e inizializzando la visualizzazione dei grafici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importiamo le librerie di base, calcolo e per la visualizzazione\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importiamo dal framework per il Deep Learning \"Keras\", in questo caso\n",
    "# basato su backend Tensorflow, un modello base di Deep Neural Network\n",
    "# e della tipologia di Layer di neuroni che intendiamo usare per costruirla.\n",
    "# In questo caso, useremo dei Layer di tipo \"Dense\" e dei neuroni\n",
    "# di tipo \"ReLU\" per i Deep Layers e \"Sigmoid\" per il neurone di output\n",
    "# che ci fornirà la previsione finale relativamente ai passeggeri\n",
    "# di cui ci verrà chiesto di stimare la sopravvivenza\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Importiamo dalla Libreria per il Machine Learning \"Scikit Learn\"\n",
    "# la funzione \"Standard Scaler\" che ci permette di normalizzare Colonne\n",
    "# Scalari in un Dataframe, riducendone i valori contenuti ad un range\n",
    "# che va da -1 a +1 in maniera ragionata. Maggiori dettagli sull'utilizzo\n",
    "# di questa liberia saranno riportati in seguito, al momento di applicarla.\n",
    "# Importiamo inoltre il modulo \"train_test_split\" che ci permetterà di\n",
    "# controllare la progressione e la bontà dell'apprendimento in corso. Anche\n",
    "# in questo caso, più dettagli saranno dati al momento opportuno\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Abilitiamo la visualizzazione direttamente sul nostro Notebook, per\n",
    "# poter plottare a schermo i Grafici di interesse\n",
    "%matplotlib inline\n",
    "\n",
    "# Impostiamo un Seed per la randomizzazione, in modo da poter ottenere\n",
    "# risultati coerenti ogni volta che lanciamo il nostro Notebook.\n",
    "# Se non si imposta un Seed, ogni volta che eseguiremo il nostro esercizio\n",
    "# otterremo risultati diversi, dovuti alla natura probabilistica degli\n",
    "# algoritmi utilizzati\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase di Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In qualsiasi progetto di Machine Learning oppure Deep Learning, sicuramente la fase di Data Preparation è di cruciale importanza.\n",
    "\n",
    "Spesso è la fase di Progetto che richiede più tempo per essere portata a termine, perchè comporta una vera comprensione delle informazioni contenute nel Dataset da parte dell'Analista.\n",
    "\n",
    "Inoltre, prevede un'accurata trasformazione dei Campi disponibili in formati e con modalità che favoriscano l'apprendimento della Rete Neurale o comunque del Modello del quale si sta facendo il training.\n",
    "\n",
    "Il Modello deve poter rilevare nel modo più proficuo possibile le informazioni (ovvero le cosiddette \"Features\") che noi gli passiamo, per poterne catturare i pattern più significativi ed essere successivamente in grado di effettuare previsioni su dati mai visti prima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggiamo in un Dataframe (struttura logica implementata dalla libreria Pandas che ci consente di manipolare interi Dataset molto facilmente) il file \"train.csv\" scaricato da Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il file di riferimento \"train.csv\" scaricato dal sito della\n",
    "# Kaggle Competition dovrà essere salvato nella stessa directory di questo\n",
    "# Jupyter Notebook, se stai lavorando in locale. Se invece stai lavorando\n",
    "# sull'Istanza Google Colab come suggerito nell'articolo, non devi fare nulla\n",
    "# in quanto il file stesso è già stato scaricato ed è già presente nella\n",
    "# posizione corretta\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizziamo alcune righe del nostro Dataframe di Train, per renderci conto delle Colonne che lo compongono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "15           16         1       2   \n",
       "16           17         0       3   \n",
       "17           18         1       2   \n",
       "18           19         0       3   \n",
       "19           20         1       3   \n",
       "20           21         0       2   \n",
       "21           22         1       2   \n",
       "22           23         1       3   \n",
       "23           24         1       1   \n",
       "24           25         0       3   \n",
       "25           26         1       3   \n",
       "26           27         0       3   \n",
       "27           28         0       1   \n",
       "28           29         1       3   \n",
       "29           30         0       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                   Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                               Rice, Master. Eugene    male   2.0      4   \n",
       "17                       Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                            Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                               Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                              Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                        McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                       Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                      Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25  Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                            Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                     Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                      O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                Todoroff, Mr. Lalio    male   NaN      0   \n",
       "\n",
       "    Parch            Ticket      Fare        Cabin Embarked  \n",
       "0       0         A/5 21171    7.2500          NaN        S  \n",
       "1       0          PC 17599   71.2833          C85        C  \n",
       "2       0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3       0            113803   53.1000         C123        S  \n",
       "4       0            373450    8.0500          NaN        S  \n",
       "5       0            330877    8.4583          NaN        Q  \n",
       "6       0             17463   51.8625          E46        S  \n",
       "7       1            349909   21.0750          NaN        S  \n",
       "8       2            347742   11.1333          NaN        S  \n",
       "9       0            237736   30.0708          NaN        C  \n",
       "10      1           PP 9549   16.7000           G6        S  \n",
       "11      0            113783   26.5500         C103        S  \n",
       "12      0         A/5. 2151    8.0500          NaN        S  \n",
       "13      5            347082   31.2750          NaN        S  \n",
       "14      0            350406    7.8542          NaN        S  \n",
       "15      0            248706   16.0000          NaN        S  \n",
       "16      1            382652   29.1250          NaN        Q  \n",
       "17      0            244373   13.0000          NaN        S  \n",
       "18      0            345763   18.0000          NaN        S  \n",
       "19      0              2649    7.2250          NaN        C  \n",
       "20      0            239865   26.0000          NaN        S  \n",
       "21      0            248698   13.0000          D56        S  \n",
       "22      0            330923    8.0292          NaN        Q  \n",
       "23      0            113788   35.5000           A6        S  \n",
       "24      1            349909   21.0750          NaN        S  \n",
       "25      5            347077   31.3875          NaN        S  \n",
       "26      0              2631    7.2250          NaN        C  \n",
       "27      2             19950  263.0000  C23 C25 C27        S  \n",
       "28      0            330959    7.8792          NaN        Q  \n",
       "29      0            349216    7.8958          NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eseguendo l'estrazione dal Dataframe di Train, si potrà notare che molti record\n",
    "# contengono campi valorizzati a \"NULL\" (dove si vede indicato \"NaN\" ovvero \"Not a\n",
    "# Number\"). Quando si fa il Training di un Modello usando un Dataset, non è mai buona\n",
    "# cosa avere dei dati mancanti, perchè stiamo dando delle informazioni poco precise\n",
    "# e quando ci troveremo ad usare il nostro Modello per fare previsioni su Dati\n",
    "# mai visti prima, la capacità di generalizzare e la conseguente precisione dei\n",
    "# risultati ne risentiranno.\n",
    "# Vedremo nel proseguo che nel corso della nostra fase di Data Preparation ci\n",
    "# prenderemo cura di sostituire questi dati mancanti con valori opportuni oppure,\n",
    "# laddove questo non fosse possibile, elimineremo i relativi record. Questo ci\n",
    "# consentirà un migliore training del nostro Modello\n",
    "train.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizziamo la Distribuzione per Età dei passeggeri in ognuna delle tre Classi di Viaggio della nave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come abbiamo potuto notare poc'anzi visualizzando il nostro Dataframe di Test, che dobbiamo usare per l'apprendimento del nostro Mofdello, una delle informazioni fondamentali, ovvero l'Età del Passeggero, in parecchi casi risulta essere assente.\n",
    "\n",
    "Questo è senz'altro un problema a cui dobbiamo porre rimedio. Dobbiamo integrare quest'informazione mancante in maniera ragionata. Per poterlo fare cominciamo quindi con lo stimare qual e' la Distribuzione per Eta' dei Passeggeri nelle tre Classi della nave usando le informazioni che invece sono presenti.\n",
    "\n",
    "Visualizzeremo questa informazione tramite un \"Box Chart\", molto adatto a fornire un colpo d'occhio immediato per questo tipo di informazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13767d750>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizziamo la Distribuzione per Eta' dei Passeggeri nelle tre Classi della nave\n",
    "# tramite un \"Box Chart\", molto adatto a fornire un colpo d'occhio immediato per\n",
    "# questo tipo di informazioni\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.boxplot(x='Pclass', y='Age', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dalla visualizzazione precedente possiamo intuire qual è l'età media dei Passeggeri in ogni Classe di Viaggio della nave e possiamo quindi scrivere una funzione che ci permetta, laddove il dato dell'età sia mancante nel nostro Dataset, di integrarlo in maniera ragionata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questa funzione riceve in input una Tupla \"Età\" + \"Classe di Viaggio\"\n",
    "# e, laddove il campo \"Età\" non risulti essere valorizzato, restituisce\n",
    "# un vlaore di default stimato in base alle nostre stime che sono\n",
    "# state spiegate poc'anzi in questo stesso Jupyter Notebook\n",
    "def assegna_eta(tupla_valori):\n",
    "    Age = tupla_valori[0]\n",
    "    Pclass = tupla_valori[1]\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "\n",
    "        if Pclass == 1:\n",
    "            return 37\n",
    "\n",
    "        elif Pclass == 2:\n",
    "            return 29\n",
    "\n",
    "        else:\n",
    "            return 24\n",
    "\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applichiamo la funzione appena scritta al nostro Dataset, e assegnamo un'Età di default ai Passeggeri privi di tale informazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifica in-place il nostro Dataframe di riferimento, applicando\n",
    "# la funzione che integra l'Età del Passeggero laddove mancante\n",
    "train['Age'] = train[['Age','Pclass']].apply(assegna_eta,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il campo \"Età\" è stato sistemato, ma ci accorgiamo che nel campo \"Cabina\" abbiamo un grande numero di valori \"NULL\". In questo caso, stimare un valore di default è impresa praticamente impossibile, e comunque non appare di fondamentale importanza categorizzare la \"Cabina\" del Passeggero in esame ai fini di far apprendere il nostro Algoritmo. Si decide quindi di eliminare completamente la Colonna dal Dataset, così come eliminiamo anche altre due Colonne contenenti informazioni non strutturate e di dubbia utilità per il Training, ovvero \"Ticket\" e ovviamente \"PassengerId\", in quando l'ID del Passeggero non è utile in questa fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop delle Colonne non utilizzabili o non interessanti\n",
    "train.drop('Cabin',axis=1,inplace=True)\n",
    "train.drop('Ticket',axis=1,inplace=True)\n",
    "train.drop('PassengerId',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A questo punto tutti i Campi con valore \"NULL\" dovrebbero essere stati trattati, in un modo o nell'altro. Per accertarci che non restino ulteriori Record spuri, eseguiamo la seguente riga di codice che elimina dal Dataframe qualsiasi ulteriore riga contenete \"NULL\" che dovesse essere rimasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop di qualsiasi Colonna sia rimasta con valori \"NULL\"\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possiamo a questo punto ispezionare visivamente un campione del Dataframe di Train, per capire come sia stato trasformato nel corso delle operazioni effettuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Fare Embarked  \n",
       "0    male  22.0      1      0   7.2500        S  \n",
       "1  female  38.0      1      0  71.2833        C  \n",
       "2  female  26.0      0      0   7.9250        S  \n",
       "3  female  35.0      1      0  53.1000        S  \n",
       "4    male  35.0      0      0   8.0500        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processiamo ora il campo \"Name\", per trasformarlo in un campo Categorical, quindi molto utile da dare in pasto al nosto Modello ai fini del Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il Campo \"Name\" contiene informazioni quali:\n",
    "\n",
    "- Il Titolo (es. \"Mr\" oppure \"Mrs\" o ancora \"Ms\", spesso indicante il fatto se il Passeggero è sposato oppure no\n",
    "- Se è ad esempio un Ufficiale, o se ha incarichi sociali particolari\n",
    "- Se ha Titoli Nobiliari\n",
    "\n",
    "Tutto questo ci fornisce informazioni più dettagliate che meglio descrivono la Categoria di un Passeggero, andando olte il campo \"Sex\", che resta comunque semanticamente importantissimo.\n",
    "\n",
    "Possiamo quindi scrivere una funzione per estrarre il Titolo del Passeggero dal campo \"Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che splitta la Stringa \"Name\" ed estrae il Titolo\n",
    "# sociale del Passeggero in esame\n",
    "def ottieni_titolo(name):\n",
    "    if '.' in name:\n",
    "        return name.split(',')[1].split('.')[0].strip()\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo ora la lista dei Titoli sociali estratti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titoli sociali trovati nel dataset:\n",
      "17 : ['Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Lady', 'Major', 'Master', 'Miss', 'Mlle', 'Mme', 'Mr', 'Mrs', 'Ms', 'Rev', 'Sir', 'the Countess']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizziamo la lista dei Titoli sociali dei Passeggeri che sono\n",
    "# stati rilevati dalla nostra funzione di estrazione\n",
    "titoli = sorted(set([x for x in train.Name.map(lambda x: ottieni_titolo(x))]))\n",
    "print('Titoli sociali trovati nel dataset:')\n",
    "print(len(titoli), ':', titoli)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come spiegato prima, siamo ora in grado di convertire il campo \"Name\" (un campo non strutturato e che non offre informazioni utili all'apprendimento del Modello) in un campo di tipo \"Categorical\", strutturato e ad alto valore informativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo una Categorizzazione dei Titoli sociali, ritornando\n",
    "# per ogni Passeggero in esame se di tratta di\n",
    "# \"Mr\", \"Master\", Mrs\", \"Miss\", \"Ufficiale\", \"Nobile\"\n",
    "def codifica_titolo(record_completo):\n",
    "    titolo = record_completo['Title']\n",
    "    if titolo in ['Capt', 'Col', 'Major', 'Rev']:\n",
    "        return 'Ufficiale'\n",
    "    elif titolo in ['the Countess', 'Mme', 'Lady', 'Don', 'Dona', 'Jonkheer', 'Sir']:\n",
    "        return 'Nobile'\n",
    "    elif titolo in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif titolo =='Dr':\n",
    "        if record_completo['Sex']=='male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return titolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A questo punto possiamo applicare la funzione di Categorizzazione del Titolo sociale al nostro Dataframe di Train e creare una nuova Colonna \"Title\". Inoltre, possiamo successivamente eliminare la Colonna \"Name\", che come abbiamo visto non contiene di per sè informazioni strutturate utili al Training del Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodifichiamo la Colonna \"Name\" ed estraiamo il\n",
    "# Titolo sociale del Passeggero in esame\n",
    "train['Title'] = train['Name'].map(lambda x: ottieni_titolo(x))\n",
    "\n",
    "# Infine, rimpiazziamo il Titolo appena estratto con una sua\n",
    "# codifica Categorica ancora più strutturata\n",
    "train['Title'] = train.apply(codifica_titolo, axis=1)\n",
    "\n",
    "# Ora la colonna \"Name\", non strutturata, non ci serve\n",
    "# più ai fini dell'Apprendimento del nostro Modello, e\n",
    "# quindi la eliminamo dal Dataframe\n",
    "train.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title\n",
       "0         0       3    male  22.0      1      0   7.2500        S    Mr\n",
       "1         1       1  female  38.0      1      0  71.2833        C   Mrs\n",
       "2         1       3  female  26.0      0      0   7.9250        S  Miss\n",
       "3         1       1  female  35.0      1      0  53.1000        S   Mrs\n",
       "4         0       3    male  35.0      0      0   8.0500        S    Mr"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ispezioniamo visivamente il Dataframe risultante\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertiamo le Variabili Categoriche in valori numerici \"One-Hot Encoded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allo scopo di preparare il Dato per essere dato in pasto a un Modello per eseguirne il Training, è pratica comune nel Machine Learning effettuare quello che viene definito \"One-Hot Encoding\" delle Variabili Categoriche.\n",
    "\n",
    "Questo significa che se abbiamo una Colonna Categorica nel nostro Dataframe, ad esempio \"Title\", è necessario splittarla in un numero di colonne pari al numero di Categorie che la colonnaoriginale può assumere.\n",
    "\n",
    "Ognuna delle nuove Colonne \"Dummy\" potrà avere valore \"0\" oppure \"1\" a seconda che il Passeggero in esame rientri in quella Categoria oppure no.\n",
    "\n",
    "Per fare un esempio pratico, le possibili Categorie che troviamo nella colonna \"Title\" sono le seguenti: \"Mr\", \"Miss\", \"Master\", \"Mrs\", \"Nobile\", \"Ufficiale\".\n",
    "\n",
    "In questo caso specifico, il nostro obiettivo è, partendo dalla Colonna \"Title\", ottenere invece 6 colonne derivate, quelle elencate poc'anzi. Ognuna di tali Colonne assumerà valore \"0\" oppure \"1\" a seconda che in effetti il Passeggero in esame ricada in quella Categoria!\n",
    "\n",
    "Notermo in effetti che l'Encoding eseguito usando la Libreria Pandas creerà solo 5 colonne. Il motivo è che creare 6 colonne in effetti è inutile. 5 Colonne che valgano tutte \"0\" infatti indicano implicitamente che quel Passeggero appartiene alla sesta Categoria non elencata esplicitamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effettuiamo il \"One-Hot Encoding\" delle Variabili Categorche in modo tale che la Rete Neurale possa interpretarle correttamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguiamo ora operativamente quanto spiegato su tutte le colonne Categoriche nel nostro Dataframe, ovvero il \"Sesso\", il \"Porto di Imbarco\", il \"Titolo sociale\" e la \"Classe di Viaggio\" dei nostri Passeggeri.\n",
    "\n",
    "Avremo inoltre cura di droppare le Colonne \"originali\" che non sono \"One-Hot Encoded\".\n",
    "\n",
    "Infine, aggiorneremo la definizione del nostro Dataframe unendo alla sua destra le nuove Colonne \"One-Hot Encoded\" appena estratte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estraiamo le colonne \"One-Hot Encoded\" a partire dalle\n",
    "# Colonne Categoriche\n",
    "sex = pd.get_dummies(train['Sex'],drop_first=True)\n",
    "embark = pd.get_dummies(train['Embarked'],drop_first=True)\n",
    "title = pd.get_dummies(train['Title'],drop_first=True)\n",
    "travelclass = pd.get_dummies(train['Pclass'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminiamo le Colonne originali e uniamo al loro posto le\n",
    "# Colonne \"One-Hot Encoded\" appena create\n",
    "train.drop(['Sex', 'Embarked', 'Title', 'Pclass'],axis=1,inplace=True)\n",
    "train = pd.concat([train, sex, embark, title, travelclass],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Nobile</th>\n",
       "      <th>Ufficiale</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  male  Q  S  Miss  Mr  Mrs  Nobile  \\\n",
       "0         0  22.0      1      0   7.2500     1  0  1     0   1    0       0   \n",
       "1         1  38.0      1      0  71.2833     0  0  0     0   0    1       0   \n",
       "2         1  26.0      0      0   7.9250     0  0  1     1   0    0       0   \n",
       "3         1  35.0      1      0  53.1000     0  0  1     0   0    1       0   \n",
       "4         0  35.0      0      0   8.0500     1  0  1     0   1    0       0   \n",
       "\n",
       "   Ufficiale  2  3  \n",
       "0          0  0  1  \n",
       "1          0  0  0  \n",
       "2          0  0  1  \n",
       "3          0  0  0  \n",
       "4          0  0  1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ispezioniamo visivamente il Dataframe risultante\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridefiniamo le Colonne \"Age\" and \"Fare\" applicando la funzione Standard Scaler della Libreria SkLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando in un Dataset sono presenti Colonne che contengano valori scalari discreti che però assumano valori molto eterogenei tra loro in termini di scala (nel nostro caso, le Colonne \"Age\" e \"Fare\" ovvero il prezzo pagato per il biglietto), è pratica comune nel Machine Learning rendere omogenee queste grandezze, in modo da aiutare la Rete Neurale che su di esse deve apprendere a convergere più rapidamente e in maniera più consistente.\n",
    "\n",
    "E' pratica comune normalizzare tutti questi valori scalari in un range che vada da -1 a +1. Nei passaggi successivi implementeremo questo accorgimento che ci permetterà di ottenere migliori risultati in termini di precisione previsionale da parte del nostro Modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling della Colonna \"Age\"\n",
    "eta = train['Age'].values.reshape(train.shape[0],1)\n",
    "normalizzatore = StandardScaler()\n",
    "normalizzatore.fit(eta)\n",
    "eta_normalizzata = normalizzatore.transform(eta)\n",
    "train['Age'] = eta_normalizzata\n",
    "\n",
    "# Standard Scaling della Colonna \"Fare\"\n",
    "tariffa = train['Fare'].values.reshape(train.shape[0],1)\n",
    "normalizzatore = StandardScaler()\n",
    "normalizzatore.fit(tariffa)\n",
    "tariffa_normalizzata = normalizzatore.transform(tariffa)\n",
    "train['Fare'] = tariffa_normalizzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Nobile</th>\n",
       "      <th>Ufficiale</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.531670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.680232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.228695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.453001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.453001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.484133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived       Age  SibSp  Parch      Fare  male  Q  S  Miss  Mr  Mrs  \\\n",
       "0         0 -0.531670      1      0 -0.500240     1  0  1     0   1    0   \n",
       "1         1  0.680232      1      0  0.788947     0  0  0     0   0    1   \n",
       "2         1 -0.228695      0      0 -0.486650     0  0  1     1   0    0   \n",
       "3         1  0.453001      1      0  0.422861     0  0  1     0   0    1   \n",
       "4         0  0.453001      0      0 -0.484133     1  0  1     0   1    0   \n",
       "\n",
       "   Nobile  Ufficiale  2  3  \n",
       "0       0          0  0  1  \n",
       "1       0          0  0  0  \n",
       "2       0          0  0  1  \n",
       "3       0          0  0  0  \n",
       "4       0          0  0  1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ispezioniamo visivamente il Dataframe risultante\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il Dataframe di Apprendimento è finalmente pronto in ogni sua parte e la fase di Data Preparation è conclusa! Ora possiamo dare in pasto il nostro Dataframe alla Rete Neurale per effettuarne il Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creiamo e applichiamo la Rete Neurale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Innanzitutto, splittiamo il nostro Dataframe di apprendimento preparato con fatica in due sezioni, rispettivamente composte dall'80% e dal 20% dei Record originali.\n",
    "\n",
    "Questo perchè è pratica comune nel Machine Learning tenersi da parte un subset dei Record di cui comunque conosciamo la Class Label (ovvero, nel nostro caso, il flag \"Survived\" che ci dice se il Passeggero è sopravvissuto oppure no.\n",
    "\n",
    "Man mano che il Training procede, potremo utilizzare il nostro Subset di Validazione (costituito quindi da dati che avremo artificiosamente nascosto alla Rete Neurale che sta apprendendo) e simulare una Previsione della Class Label.\n",
    "\n",
    "Potremo a questo punto confrontare la Predizione inferita dalla Rete Neurale con il valore \"vero\", e capire se la Previsione è stata corretta oppure no. Ripetendo questa operazione su tutto il Dataframe di Validazione, potremo stimare la \"Validation Accuracy\" del nostro Modello.\n",
    "\n",
    "Man mano che il Training procede, ci potremo aspettare senz'altro un incremento sulla Accuracy di Training, perchè sono dati dei quali la Rete Neurale conosce e \"utilizza\" la Class Label per migliorarsi. Ma dovremo anche verificare che di pari passo otteniamo un miglioramento anche sulle Previsioni inferite dal Set di Validazione, ovvero su dati che la Rete \"non conosce\". Questo non è scontato, ma è il vero segnale che il nostro Modello sta imparando a \"generalizzare\", e sarà quindi usabile con successo nel mondo reale.\n",
    "\n",
    "Nel nostro caso, per prevedere correttamente i risultati utili per piazzarsi bene nella Competition!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepariamo il Set di Training e il Set di Validazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepariamo un Dataframe che contiene le sole Class Label a noi note, \"y\", e un Dataframe che contiene il resto dei Campi.\n",
    "\n",
    "Usando la funzione \"train_test_split\" della Libreria Scikit Learn, spezziamo infine questi Set in Subset di \"Train\" vero e proprio e in Set di \"Validazione\", in proporzione di 80% - 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estraiamo le Class Label dal Dataframe totale (Colonna \"Survived\")\n",
    "# in un nuovo Dataframe contenente, quindi, i soli risultati corretti\n",
    "y = train['Survived']\n",
    "\n",
    "# Eliminiamo la colonna con la Class Label dal Dataframe originale\n",
    "X = train.drop('Survived', axis=1)\n",
    " \n",
    "# Splittiamo i Set appena ottenuti in \"Training\" e \"Validation\"\n",
    "# in proporzione 80% - 20%\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione Set di Train: (711, 14)\n",
      "Dimensione Set di Validazione: (178, 14)\n",
      "Dimensione Set Class Labels di Train: (711,)\n",
      "Dimensione Set Class Labels di Validazione: (178,)\n"
     ]
    }
   ],
   "source": [
    "# Visualizziamo le Dimensioni effettive dei nosti Set di dati:\n",
    "print(\"Dimensione Set di Train: \" + str(X_tr.shape))\n",
    "print(\"Dimensione Set di Validazione: \" + str(X_va.shape))\n",
    "print(\"Dimensione Set Class Labels di Train: \" + str(y_tr.shape))\n",
    "print(\"Dimensione Set Class Labels di Validazione: \" + str(y_va.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Nobile</th>\n",
       "      <th>Ufficiale</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.380182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.484133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-0.758902</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.441435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>-0.380182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.490173</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>-0.380182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.484133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2.195110</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.634368</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  SibSp  Parch      Fare  male  Q  S  Miss  Mr  Mrs  Nobile  \\\n",
       "121 -0.380182      0      0 -0.484133     1  0  1     0   1    0       0   \n",
       "687 -0.758902      0      0 -0.441435     1  0  1     0   1    0       0   \n",
       "790 -0.380182      0      0 -0.490173     1  1  0     0   1    0       0   \n",
       "837 -0.380182      0      0 -0.484133     1  0  1     0   1    0       0   \n",
       "659  2.195110      0      2  1.634368     1  0  0     0   1    0       0   \n",
       "\n",
       "     Ufficiale  2  3  \n",
       "121          0  0  1  \n",
       "687          0  0  1  \n",
       "790          0  0  1  \n",
       "837          0  0  1  \n",
       "659          0  0  0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo un estratto del Set di Training\n",
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121    0\n",
       "687    0\n",
       "790    0\n",
       "837    0\n",
       "659    0\n",
       "      ..\n",
       "716    1\n",
       "768    0\n",
       "73     0\n",
       "236    0\n",
       "37     0\n",
       "Name: Survived, Length: 711, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo un estratto del Set di Class Labels di Training\n",
    "y_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the first layer dimensions to equal the number of features in your data set. In this case, the first layer expects eleven values. Feel free to play with the number of layers and neurons in every layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La nostra Rete Neurale avrà le seguenti caratteristiche:\n",
    "\n",
    "- Dimensione dell'Input Layer uguale al numero delle Fatures presenti nel nostro Set di Training, in questo caso 14\n",
    "- Quattro Deep Layer di tipo \"Dense\" (ovvero dove ognuno dei Neuroni è connesso con tutti i Neuroni del Layer successivo)\n",
    "- Un Neurone di Output che si andrà a leggere e che ci fornirà a tutti gli effetti la Previsione se il Passeggero sottoposto in Input sopravviverà o meno\n",
    "- I Layer Deep saranno composti da Neuroni con Funzione di Attivazione di tipo \"ReLU\"\n",
    "- Il Layer di Output sarà composto da un Neurone con Funzione di Attivazione di tipo \"Sigmoid\"\n",
    "- I Layer Deep saranno composti rispettivamente da 20, 15, 10 e 10 Neuroni\n",
    "\n",
    "Non è scopo del presente esercizio approfindire il significato e i casi di utilizzo delle Funzioni di Attivazione dei singoli Neuroni. Per questo, si rimanda a un prossimo articolo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo la Rete Neurale che andremo ad addestrare\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=14, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizziamo ora lo Schema effettivo della Rete Neurale che abbiamo costruito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per meglio comprendere cosa stiamo facendo, visualizziamo a tutti gli effetti lo Schema Logico della Rete Neurale. Questo il Summary schematico del Modello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                300       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Visualizziamo il Summary del Modello\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiliamo il nostro Modello di Rete Neurale, usando una Loss Function di tipo \"Binary Crossentropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di avviare l'apprendimento, dobbiamo compilare il nostro Modello. In questo caso, visto che ciò che dobbiamo prevedere in Output è fondamentalmente una Classe binaria \"1\" oppure \"0\", usiamo una Loss Funcrion di tipo \"Binary Crossentropy\", perfetta per l'uso in questa casistica.\n",
    "\n",
    "Usermemo un Ottimizzatore di tipo \"Adam\".\n",
    "\n",
    "Non è scopo di questo esercizio approfondire le tipologie di Loss Fuction e le loro possibili applicazioni, e neppure le tipologie di Ottimizzatore disponibili o il loro funzionamento.\n",
    "\n",
    "Per questi argomenti si rimanda a un prossimo articolo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiliamo il Modello\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente, avviamo l'Apprendimento!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siamo giunti al momento cruciale, ovvero il Training del nostro Modello.\n",
    "\n",
    "Quello che stiamo per dire alla nostra Rete Neurale di eseguire è di:\n",
    "\n",
    "- Leggere il Set di Test e apprendere su di esso\n",
    "- Leggerlo in chunk composti da 10 Record\n",
    "- Per verificare le Performance delle Previsioni su Dati non visti, usa il Set di Validazione\n",
    "- Ripetere il tutto per 14 volte (Epochs)\n",
    "- Salva la progressione di Apprendimento in un oggetto \"history\" in modo che poi potremo plottarne un Grafico\n",
    "\n",
    "Partiamo! Eseguiamo quindi la cella successiva e attendiamo il completamento delle 14 Epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711 samples, validate on 178 samples\n",
      "Epoch 1/14\n",
      "711/711 [==============================] - 0s 435us/step - loss: 0.6709 - accuracy: 0.5963 - val_loss: 0.6352 - val_accuracy: 0.5899\n",
      "Epoch 2/14\n",
      "711/711 [==============================] - 0s 128us/step - loss: 0.5912 - accuracy: 0.6245 - val_loss: 0.5651 - val_accuracy: 0.5955\n",
      "Epoch 3/14\n",
      "711/711 [==============================] - 0s 121us/step - loss: 0.5435 - accuracy: 0.6428 - val_loss: 0.5380 - val_accuracy: 0.6685\n",
      "Epoch 4/14\n",
      "711/711 [==============================] - 0s 118us/step - loss: 0.5127 - accuracy: 0.7876 - val_loss: 0.4959 - val_accuracy: 0.8146\n",
      "Epoch 5/14\n",
      "711/711 [==============================] - 0s 113us/step - loss: 0.4691 - accuracy: 0.8031 - val_loss: 0.4377 - val_accuracy: 0.8315\n",
      "Epoch 6/14\n",
      "711/711 [==============================] - 0s 112us/step - loss: 0.4414 - accuracy: 0.8200 - val_loss: 0.4104 - val_accuracy: 0.8315\n",
      "Epoch 7/14\n",
      "711/711 [==============================] - 0s 115us/step - loss: 0.4233 - accuracy: 0.8214 - val_loss: 0.4002 - val_accuracy: 0.8315\n",
      "Epoch 8/14\n",
      "711/711 [==============================] - 0s 113us/step - loss: 0.4161 - accuracy: 0.8312 - val_loss: 0.3953 - val_accuracy: 0.8371\n",
      "Epoch 9/14\n",
      "711/711 [==============================] - 0s 115us/step - loss: 0.4060 - accuracy: 0.8368 - val_loss: 0.3910 - val_accuracy: 0.8371\n",
      "Epoch 10/14\n",
      "711/711 [==============================] - 0s 115us/step - loss: 0.4041 - accuracy: 0.8397 - val_loss: 0.3823 - val_accuracy: 0.8315\n",
      "Epoch 11/14\n",
      "711/711 [==============================] - 0s 111us/step - loss: 0.3981 - accuracy: 0.8397 - val_loss: 0.3801 - val_accuracy: 0.8483\n",
      "Epoch 12/14\n",
      "711/711 [==============================] - 0s 111us/step - loss: 0.3950 - accuracy: 0.8411 - val_loss: 0.3759 - val_accuracy: 0.8427\n",
      "Epoch 13/14\n",
      "711/711 [==============================] - 0s 115us/step - loss: 0.3929 - accuracy: 0.8368 - val_loss: 0.3781 - val_accuracy: 0.8483\n",
      "Epoch 14/14\n",
      "711/711 [==============================] - 0s 113us/step - loss: 0.3894 - accuracy: 0.8425 - val_loss: 0.3796 - val_accuracy: 0.8427\n"
     ]
    }
   ],
   "source": [
    "# Eseguiamo il fitting del nostro Modello sul Set di Training e di Validazione\n",
    "history = model.fit(X_tr, y_tr, validation_data=(X_va, y_va), epochs=14, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plottiamo la Accuracy e la Loss Function con il progredire delle Epochs di Apprendimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per renderci conto di quanto \"bene\" oppure \"male\" stiamo facendo, iniziamo col plottare un Grafico relativo alla Accuracy (Precisione) del nostro Modello, nel corso delle 14 Epochs di Training.\n",
    "\n",
    "In particolare plottiamo l'Accuracy sia con riferimento ai dati di Training stessi, che con riferimento ai dati di Validazione (che come è facile intuire, sono il vero \"banco di prova\" del Modello, visto che sono dati che non vengono usati per il Training ma sono dati \"mai vosti prima\" dalla Rete Neurale.\n",
    "\n",
    "Come si può immaginare, un'alta Accuracy è \"una buona cosa\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plottiamo l'Accuracy sul Set di Train e sul Set di Validazione\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plottiamo ora l'andamento della Loss Function, con riferimento sia al Set di Train che a quello di Validazione, della Loss Function, ovvero della quantificazione di quanto \"il Modello si è sbagliato\" nelle sue Previsioni, siano esse state effettuate sul Set di Train o su quello di Validazione.\n",
    "\n",
    "Come si può intuire, un basso valore della Loss Function implica che \"stiamo facendo bene\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plottiamo la Loss Function sul Set di Train e sul Set di Validazione\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'Accuracy sembra veramente buona sia sul Set di Train che su quello di Validazione! E anche la Loss Function appare convergere molto bene!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I grafici di cui sopra appaiono molto confortanti. Vediamo ora di dare un valore numerico preciso alle Performance che abbiamo raggiunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - 0s 14us/step\n",
      "Estimated model Loss on its own Training Data: 0.38\n",
      "Estimated model Accuracy on its own Training Data: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Eseguiamo un ciclo di Predizioni (senza ulteriore apprendimento!) sui\n",
    "# dati di Training per stimare la Precisione raggiunta in termini numerici\n",
    "tr_tot_loss, tr_tot_accuracy = model.evaluate(X_tr, y_tr)\n",
    "print('Estimated model Loss on its own Training Data: %.2f' % (tr_tot_loss))\n",
    "print('Estimated model Accuracy on its own Training Data: %.2f' % (tr_tot_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 27us/step\n",
      "Estimated model Loss on its own Validation Data: 0.38\n",
      "Estimated model Accuracy on its own Validation Data: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Eseguiamo un ciclo di Predizioni (senza ulteriore apprendimento!) sui\n",
    "# dati di Validazione per stimare la Precisione raggiunta in termini numerici\n",
    "va_tot_loss, va_tot_accuracy = model.evaluate(X_va, y_va)\n",
    "print('Estimated model Loss on its own Validation Data: %.2f' % (va_tot_loss))\n",
    "print('Estimated model Accuracy on its own Validation Data: %.2f' % (va_tot_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le Performance appaiono veramente buone sia sul Set di Training che su quello di Validazione. Siamo pronti ora per la fase finale: DARE IN PASTO ALLA RETE NEURALE I DATI DELLA COMPETITION, FORNITI DA KAGGLE, E DEI QUALI NON CONOSCIAMO ASSOLUTAMENTE IL VALORE DEL FLAG \"SURVIVED\"! Verremo quindi valutati sui nostri risultati effettivi dopo aver fatto l'Upload delle nostre Previsioni, in formato CSV, sul sito di Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creiamo la Submission per Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicheremo ora il nostro Modello ai dati di Test inizialmente scaricati dal sito della Competition, ovvero utilizzando il file \"test.csv\", che è in tutto e per tutto uguale al file \"train.csv\" che abbiamo usato per l'Apprendimento, con l'unica differenza che non contiene il Campo dei risultati, ovvero il Campo \"Survived\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggiamo i Dati di Test in un Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sulla falsariga di quanto già fatto in precedenza per i dati di \"Train\", leggiamo ora i dati di \"Test\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il file di riferimento \"test.csv\" scaricato dal sito della\n",
    "# Kaggle Competition dovrà essere salvato nella stessa directory di questo\n",
    "# Jupyter Notebook, se stai lavorando in locale. Se invece stai lavorando\n",
    "# sull'Istanza Google Colab come suggerito nell'articolo, non devi fare nulla\n",
    "# in quanto il file stesso è già stato scaricato ed è già presente nella\n",
    "# posizione corretta\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# C'è un \"NULL\" nella Colonna \"Fare\" al Record 152, sistemiamola\n",
    "test.loc[152,'Fare'] = 7\n",
    "\n",
    "# Salviamo anche una copia fisica di Riferimento del Dataframe, che ci verrà\n",
    "# utile più tardi quando dovremo recuperare la Colonna \"PassengerId\"\n",
    "test_riferimento = test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessiamo i Dati, esattamente come fatto nella fase di Data Preparation, per essere pronti a darli in pasto al nostro Modello per inferire le Previsioni da sottoporre a Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che abbiamo i Dati oggetto della Competition, dobbiamo preprocessarli per poter effettuare le Previsioni. Fortunatamente, ora sappiamo già tutti gli step necessari da seguire e li possiamo eseguire in una sola volta, tutti, in un'unica casella di Codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifica in-place il nostro Dataframe di riferimento, applicando\n",
    "# la funzione che integra l'Età del Passeggero laddove mancante\n",
    "test['Age'] = test[['Age','Pclass']].apply(assegna_eta,axis=1)\n",
    "\n",
    "# Drop delle Colonne non utilizzabili o non interessanti\n",
    "test.drop('Cabin',axis=1,inplace=True)\n",
    "test.drop('Ticket',axis=1,inplace=True)\n",
    "test.drop('PassengerId',axis=1,inplace=True)\n",
    "\n",
    "# Decodifichiamo la Colonna \"Name\" ed estraiamo il\n",
    "# Titolo sociale del Passeggero in esame\n",
    "test['Title'] = test['Name'].map(lambda x: ottieni_titolo(x))\n",
    "\n",
    "# Infine, rimpiazziamo il Titolo appena estratto con una sua\n",
    "# codifica Categorica ancora più strutturata\n",
    "test['Title'] = test.apply(codifica_titolo, axis=1)\n",
    "\n",
    "# Ora la colonna \"Name\", non strutturata, non ci serve\n",
    "# più ai fini dell'Apprendimento del nostro Modello, e\n",
    "# quindi la eliminamo dal Dataframe\n",
    "test.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Estraiamo le colonne \"One-Hot Encoded\" a partire dalle\n",
    "# Colonne Categoriche\n",
    "sex = pd.get_dummies(test['Sex'],drop_first=True)\n",
    "embark = pd.get_dummies(test['Embarked'],drop_first=True)\n",
    "title = pd.get_dummies(test['Title'],drop_first=True)\n",
    "travelclass = pd.get_dummies(test['Pclass'],drop_first=True)\n",
    "\n",
    "# Eliminiamo le Colonne originali e uniamo al loro posto le\n",
    "# Colonne \"One-Hot Encoded\" appena create\n",
    "test.drop(['Sex', 'Embarked', 'Title', 'Pclass'],axis=1,inplace=True)\n",
    "test = pd.concat([test, sex, embark, title, travelclass],axis=1)\n",
    "\n",
    "# Standard Scaling della Colonna \"Age\"\n",
    "eta = test['Age'].values.reshape(test.shape[0],1)\n",
    "normalizzatore = StandardScaler()\n",
    "normalizzatore.fit(eta)\n",
    "eta_normalizzata = normalizzatore.transform(eta)\n",
    "test['Age'] = eta_normalizzata\n",
    "\n",
    "# Standard Scaling della Colonna \"Fare\"\n",
    "tariffa = test['Fare'].values.reshape(test.shape[0],1)\n",
    "normalizzatore = StandardScaler()\n",
    "normalizzatore.fit(tariffa)\n",
    "tariffa_normalizzata = normalizzatore.transform(tariffa)\n",
    "test['Fare'] = tariffa_normalizzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Nobile</th>\n",
       "      <th>Ufficiale</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.497023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.371615</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.511885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.535433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.463715</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.180141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.482087</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.568080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.417112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp  Parch      Fare  male  Q  S  Miss  Mr  Mrs  Nobile  \\\n",
       "0  0.401768      0      0 -0.497023     1  1  0     0   1    0       0   \n",
       "1  1.371615      1      0 -0.511885     0  0  1     0   0    1       0   \n",
       "2  2.535433      0      0 -0.463715     1  1  0     0   1    0       0   \n",
       "3 -0.180141      0      0 -0.482087     1  0  1     0   1    0       0   \n",
       "4 -0.568080      1      1 -0.417112     0  0  1     0   0    1       0   \n",
       "\n",
       "   Ufficiale  2  3  \n",
       "0          0  0  1  \n",
       "1          0  0  1  \n",
       "2          0  1  0  \n",
       "3          0  0  1  \n",
       "4          0  0  1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ispezioniamo visivamente il Dataframe risultante\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applichiamo il nosto Modello (già Addestrato!) di Rete Neurale, ed effettuiamo le nostre Previsioni sui Passeggeri oggetto del Contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il Set di Test a partire dal Dataframe preprocessato poc'anzi\n",
    "X_te = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo le dimentsioni del Set di Test\n",
    "X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facciamo ora inferenza della Probabilità di Sopravvivenza di ognuno dei Passeggeri elencati nel Set di Test, utilizzando la Forward Propagation attraverso il nostro Modello di Rete Neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo le Previsioni!\n",
    "probabilita_di_sopravvivenza = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06693923],\n",
       "       [0.5552026 ],\n",
       "       [0.06754205],\n",
       "       [0.11283877],\n",
       "       [0.6356497 ],\n",
       "       [0.12203357],\n",
       "       [0.6817063 ],\n",
       "       [0.08713052],\n",
       "       [0.8456787 ],\n",
       "       [0.12373477],\n",
       "       [0.11134979],\n",
       "       [0.23202205],\n",
       "       [0.92233425],\n",
       "       [0.13709983],\n",
       "       [0.942581  ],\n",
       "       [0.94927424],\n",
       "       [0.0735015 ],\n",
       "       [0.17154303],\n",
       "       [0.2702657 ],\n",
       "       [0.5766615 ],\n",
       "       [0.3717441 ],\n",
       "       [0.8451718 ],\n",
       "       [0.90183973],\n",
       "       [0.2512516 ],\n",
       "       [0.9345063 ],\n",
       "       [0.12008134],\n",
       "       [0.88167286],\n",
       "       [0.17074442],\n",
       "       [0.25069684],\n",
       "       [0.1593737 ],\n",
       "       [0.13714924],\n",
       "       [0.11628291],\n",
       "       [0.40960366],\n",
       "       [0.5698452 ],\n",
       "       [0.40802363],\n",
       "       [0.1725167 ],\n",
       "       [0.33827725],\n",
       "       [0.358162  ],\n",
       "       [0.11235541],\n",
       "       [0.13184622],\n",
       "       [0.0815779 ],\n",
       "       [0.25186014],\n",
       "       [0.11202535],\n",
       "       [0.9406076 ],\n",
       "       [0.93828994],\n",
       "       [0.11175856],\n",
       "       [0.2666701 ],\n",
       "       [0.09613067],\n",
       "       [0.9391466 ],\n",
       "       [0.3386389 ],\n",
       "       [0.25210097],\n",
       "       [0.11050835],\n",
       "       [0.87722826],\n",
       "       [0.90564644],\n",
       "       [0.11292726],\n",
       "       [0.08993661],\n",
       "       [0.11371759],\n",
       "       [0.1116547 ],\n",
       "       [0.14212352],\n",
       "       [0.98817486],\n",
       "       [0.1167157 ],\n",
       "       [0.08158633],\n",
       "       [0.11513069],\n",
       "       [0.76875937],\n",
       "       [0.6947126 ],\n",
       "       [0.9456599 ],\n",
       "       [0.79867446],\n",
       "       [0.23664427],\n",
       "       [0.31968248],\n",
       "       [0.89046836],\n",
       "       [0.75176215],\n",
       "       [0.11069262],\n",
       "       [0.30829835],\n",
       "       [0.31564605],\n",
       "       [0.9851873 ],\n",
       "       [0.36648118],\n",
       "       [0.11140791],\n",
       "       [0.94910294],\n",
       "       [0.07922533],\n",
       "       [0.75176215],\n",
       "       [0.907827  ],\n",
       "       [0.29880103],\n",
       "       [0.22234008],\n",
       "       [0.11134979],\n",
       "       [0.07951072],\n",
       "       [0.18983287],\n",
       "       [0.72276175],\n",
       "       [0.38389036],\n",
       "       [0.75176215],\n",
       "       [0.97727513],\n",
       "       [0.55871445],\n",
       "       [0.11130428],\n",
       "       [0.82024074],\n",
       "       [0.11140791],\n",
       "       [0.29768738],\n",
       "       [0.11170977],\n",
       "       [0.978912  ],\n",
       "       [0.11336219],\n",
       "       [0.36558628],\n",
       "       [0.11296019],\n",
       "       [0.93871343],\n",
       "       [0.10668415],\n",
       "       [0.09613067],\n",
       "       [0.11210072],\n",
       "       [0.8324369 ],\n",
       "       [0.11865166],\n",
       "       [0.10382551],\n",
       "       [0.09613067],\n",
       "       [0.11165789],\n",
       "       [0.08331674],\n",
       "       [0.1363706 ],\n",
       "       [0.7518233 ],\n",
       "       [0.88047385],\n",
       "       [0.7940378 ],\n",
       "       [0.972135  ],\n",
       "       [0.19196284],\n",
       "       [0.16878542],\n",
       "       [0.7541001 ],\n",
       "       [0.31668192],\n",
       "       [0.9574503 ],\n",
       "       [0.94615304],\n",
       "       [0.12514949],\n",
       "       [0.9247164 ],\n",
       "       [0.11270207],\n",
       "       [0.09613067],\n",
       "       [0.42212948],\n",
       "       [0.11052057],\n",
       "       [0.35976097],\n",
       "       [0.09894297],\n",
       "       [0.11140791],\n",
       "       [0.11385411],\n",
       "       [0.36984354],\n",
       "       [0.45394757],\n",
       "       [0.18650141],\n",
       "       [0.10885471],\n",
       "       [0.11133406],\n",
       "       [0.16673335],\n",
       "       [0.07522237],\n",
       "       [0.34584272],\n",
       "       [0.01059502],\n",
       "       [0.08467448],\n",
       "       [0.9671427 ],\n",
       "       [0.18906954],\n",
       "       [0.08306381],\n",
       "       [0.2459017 ],\n",
       "       [0.10028431],\n",
       "       [0.26223546],\n",
       "       [0.11061576],\n",
       "       [0.25186014],\n",
       "       [0.29397452],\n",
       "       [0.90479136],\n",
       "       [0.16961199],\n",
       "       [0.0899573 ],\n",
       "       [0.32930297],\n",
       "       [0.09159142],\n",
       "       [0.11121953],\n",
       "       [0.9819156 ],\n",
       "       [0.34604263],\n",
       "       [0.24590176],\n",
       "       [0.6289382 ],\n",
       "       [0.7517272 ],\n",
       "       [0.8973988 ],\n",
       "       [0.8800093 ],\n",
       "       [0.11101264],\n",
       "       [0.11408114],\n",
       "       [0.54144955],\n",
       "       [0.26372376],\n",
       "       [0.09941834],\n",
       "       [0.8902812 ],\n",
       "       [0.35188314],\n",
       "       [0.11121953],\n",
       "       [0.16663483],\n",
       "       [0.14255208],\n",
       "       [0.16923377],\n",
       "       [0.01495081],\n",
       "       [0.95739007],\n",
       "       [0.925269  ],\n",
       "       [0.3685252 ],\n",
       "       [0.7088606 ],\n",
       "       [0.82505584],\n",
       "       [0.07922533],\n",
       "       [0.34468913],\n",
       "       [0.91033185],\n",
       "       [0.09613067],\n",
       "       [0.9708021 ],\n",
       "       [0.09704289],\n",
       "       [0.91383904],\n",
       "       [0.12222326],\n",
       "       [0.02440545],\n",
       "       [0.09485391],\n",
       "       [0.12383461],\n",
       "       [0.2512374 ],\n",
       "       [0.77296036],\n",
       "       [0.06863376],\n",
       "       [0.9592943 ],\n",
       "       [0.11288735],\n",
       "       [0.95756024],\n",
       "       [0.38358867],\n",
       "       [0.07496077],\n",
       "       [0.8047863 ],\n",
       "       [0.76748544],\n",
       "       [0.9430296 ],\n",
       "       [0.703688  ],\n",
       "       [0.9595298 ],\n",
       "       [0.07352293],\n",
       "       [0.30100864],\n",
       "       [0.61888474],\n",
       "       [0.07348576],\n",
       "       [0.86251515],\n",
       "       [0.11174759],\n",
       "       [0.121681  ],\n",
       "       [0.11103147],\n",
       "       [0.11604694],\n",
       "       [0.909927  ],\n",
       "       [0.16730833],\n",
       "       [0.25245458],\n",
       "       [0.7520327 ],\n",
       "       [0.19656232],\n",
       "       [0.9769081 ],\n",
       "       [0.11140791],\n",
       "       [0.86886203],\n",
       "       [0.1107659 ],\n",
       "       [0.95716095],\n",
       "       [0.11064512],\n",
       "       [0.9071758 ],\n",
       "       [0.7301719 ],\n",
       "       [0.11091569],\n",
       "       [0.75176215],\n",
       "       [0.11955294],\n",
       "       [0.08712739],\n",
       "       [0.12316748],\n",
       "       [0.85659367],\n",
       "       [0.14265081],\n",
       "       [0.09614065],\n",
       "       [0.45764276],\n",
       "       [0.11239237],\n",
       "       [0.3642276 ],\n",
       "       [0.171931  ],\n",
       "       [0.9193331 ],\n",
       "       [0.962824  ],\n",
       "       [0.91462386],\n",
       "       [0.73515105],\n",
       "       [0.39015505],\n",
       "       [0.11134669],\n",
       "       [0.32155323],\n",
       "       [0.28353065],\n",
       "       [0.958007  ],\n",
       "       [0.1086193 ],\n",
       "       [0.9574503 ],\n",
       "       [0.61447614],\n",
       "       [0.9719062 ],\n",
       "       [0.11242655],\n",
       "       [0.52335924],\n",
       "       [0.11188948],\n",
       "       [0.11394861],\n",
       "       [0.11121953],\n",
       "       [0.09613067],\n",
       "       [0.11300713],\n",
       "       [0.9081453 ],\n",
       "       [0.11063522],\n",
       "       [0.13587666],\n",
       "       [0.11067286],\n",
       "       [0.906595  ],\n",
       "       [0.7561486 ],\n",
       "       [0.11100221],\n",
       "       [0.11134979],\n",
       "       [0.20744196],\n",
       "       [0.11121953],\n",
       "       [0.33827725],\n",
       "       [0.11708826],\n",
       "       [0.28494105],\n",
       "       [0.09613067],\n",
       "       [0.95589614],\n",
       "       [0.6080163 ],\n",
       "       [0.16923144],\n",
       "       [0.9143083 ],\n",
       "       [0.07622689],\n",
       "       [0.13045585],\n",
       "       [0.10978115],\n",
       "       [0.07635128],\n",
       "       [0.34521782],\n",
       "       [0.9210572 ],\n",
       "       [0.75176215],\n",
       "       [0.6646309 ],\n",
       "       [0.7362364 ],\n",
       "       [0.11458436],\n",
       "       [0.11110666],\n",
       "       [0.29660204],\n",
       "       [0.16923377],\n",
       "       [0.11140791],\n",
       "       [0.25937325],\n",
       "       [0.6811862 ],\n",
       "       [0.16923377],\n",
       "       [0.19186169],\n",
       "       [0.11644614],\n",
       "       [0.11214656],\n",
       "       [0.973104  ],\n",
       "       [0.1593737 ],\n",
       "       [0.24654135],\n",
       "       [0.1133351 ],\n",
       "       [0.11375123],\n",
       "       [0.11238715],\n",
       "       [0.07645193],\n",
       "       [0.11163908],\n",
       "       [0.75176215],\n",
       "       [0.9510684 ],\n",
       "       [0.26124692],\n",
       "       [0.94733536],\n",
       "       [0.1953161 ],\n",
       "       [0.5285426 ],\n",
       "       [0.11556894],\n",
       "       [0.17115575],\n",
       "       [0.11122897],\n",
       "       [0.5956977 ],\n",
       "       [0.9541075 ],\n",
       "       [0.80610025],\n",
       "       [0.46647912],\n",
       "       [0.08151218],\n",
       "       [0.11253098],\n",
       "       [0.11806375],\n",
       "       [0.11210072],\n",
       "       [0.16823095],\n",
       "       [0.07522237],\n",
       "       [0.23458973],\n",
       "       [0.98170984],\n",
       "       [0.11063594],\n",
       "       [0.93408096],\n",
       "       [0.28696197],\n",
       "       [0.11152217],\n",
       "       [0.07825518],\n",
       "       [0.74401176],\n",
       "       [0.29372782],\n",
       "       [0.16923144],\n",
       "       [0.7860023 ],\n",
       "       [0.11254674],\n",
       "       [0.2122285 ],\n",
       "       [0.08134803],\n",
       "       [0.05056229],\n",
       "       [0.08631775],\n",
       "       [0.6116842 ],\n",
       "       [0.08361363],\n",
       "       [0.11367801],\n",
       "       [0.02406618],\n",
       "       [0.98602366],\n",
       "       [0.3177688 ],\n",
       "       [0.41632092],\n",
       "       [0.07522237],\n",
       "       [0.58909875],\n",
       "       [0.07515231],\n",
       "       [0.87753606],\n",
       "       [0.8963448 ],\n",
       "       [0.0735229 ],\n",
       "       [0.11503178],\n",
       "       [0.08452934],\n",
       "       [0.7955729 ],\n",
       "       [0.2191776 ],\n",
       "       [0.96527386],\n",
       "       [0.11134356],\n",
       "       [0.09613067],\n",
       "       [0.43945068],\n",
       "       [0.01406997],\n",
       "       [0.94251776],\n",
       "       [0.9403869 ],\n",
       "       [0.11283877],\n",
       "       [0.8972294 ],\n",
       "       [0.28242832],\n",
       "       [0.18983456],\n",
       "       [0.3669621 ],\n",
       "       [0.8910368 ],\n",
       "       [0.11119282],\n",
       "       [0.09669679],\n",
       "       [0.96818066],\n",
       "       [0.20028296],\n",
       "       [0.10318816],\n",
       "       [0.9421843 ],\n",
       "       [0.9879688 ],\n",
       "       [0.20444435],\n",
       "       [0.07784161],\n",
       "       [0.21394378],\n",
       "       [0.14130238],\n",
       "       [0.09613067],\n",
       "       [0.09074101],\n",
       "       [0.803167  ],\n",
       "       [0.6226952 ],\n",
       "       [0.07815722],\n",
       "       [0.9287848 ],\n",
       "       [0.11130428],\n",
       "       [0.11953431],\n",
       "       [0.10381794],\n",
       "       [0.29253322],\n",
       "       [0.25592566],\n",
       "       [0.813645  ],\n",
       "       [0.68830836],\n",
       "       [0.10616478],\n",
       "       [0.0793063 ],\n",
       "       [0.91512096],\n",
       "       [0.09609213],\n",
       "       [0.9387833 ],\n",
       "       [0.11051276],\n",
       "       [0.07545945],\n",
       "       [0.9695351 ],\n",
       "       [0.12644523],\n",
       "       [0.8772782 ],\n",
       "       [0.1957829 ],\n",
       "       [0.36506778],\n",
       "       [0.11892417],\n",
       "       [0.09390727],\n",
       "       [0.37068975],\n",
       "       [0.751701  ],\n",
       "       [0.72248095],\n",
       "       [0.75176215],\n",
       "       [0.9063182 ],\n",
       "       [0.31414372],\n",
       "       [0.11140791],\n",
       "       [0.8284    ],\n",
       "       [0.11560065],\n",
       "       [0.11140794],\n",
       "       [0.45040786]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo l'Array risultante, contenente le Probabilità di\n",
    "# Sopravvivenza di ciascuno dei Passeggeri nel Set di Test\n",
    "probabilita_di_sopravvivenza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scegliamo ora una Soglia di 0.5 per creare la versione finale dell'Arrayt di Sopravvivenza, che sarà composto solo da cifre \"0\" oppure \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcoliamo l'Array finale da sottoporre a Kaggle, formato solo\n",
    "# da cifre \"0\" oppure \"1\"\n",
    "flag_di_sopravvivenza = np.zeros((X_te.shape[0]))\n",
    "for i in range(0, probabilita_di_sopravvivenza.shape[0]):\n",
    "        if probabilita_di_sopravvivenza[i] > 0.5:\n",
    "            flag_di_sopravvivenza[i] = 1\n",
    "        else:\n",
    "            flag_di_sopravvivenza[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo l'Array finale dei Flag di Sopravvivenza calcolati\n",
    "flag_di_sopravvivenza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salviamo le Predizioni in un file CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente possiamo salvare i risultati finali in un file CSV. Questo file andrà uploadato al sito della Competition, seguendo le istruzioni contenute nell'articolo correlato, per vedere la collocazione in classifica!\n",
    "\n",
    "Per fare ciò, dovremo andare a recuperare gli ID dei Passeggeri dal Set di Test, affiancarlo ai nostri Flag di Sopravvivenza calcolati, e salvare infine il Dataframe così ottenuto in formato CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estraiamo gli ID dei Passeggeri dal Set di Test originale\n",
    "# utilizzando la copia del Dataframe \"test_riferimento\" che\n",
    "# avevamo a suo tempo effettuato per conservare la\n",
    "# Colonna \"PassengerId\"\n",
    "id_passeggeri = pd.DataFrame(data=test_riferimento['PassengerId'], columns=['PassengerId'], dtype=int)\n",
    "\n",
    "# Effettuiamo la trasposizione del Dataframe delle Predizioni in\n",
    "# un vettore di Colonne\n",
    "predizioni_finali = pd.DataFrame(data=flag_di_sopravvivenza, columns=['Survived'], dtype=int)\n",
    "\n",
    "# Concateniamo i due vettori di Colonne per ottenere il Dataframe finale\n",
    "predizioni_upload_kaggle_finali = pd.concat([id_passeggeri, predizioni_finali], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ispezioniamo visivamente il Dataframe risultante\n",
    "predizioni_upload_kaggle_finali.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione del file finale e completo su Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salviamo i risultati! Questo è il file di cui fare Upload sul sito Kaggle!\n",
    "predizioni_upload_kaggle_finali.to_csv('titanic_previsioni_sopravvivenza.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' giunto il momento tanto atteso e il risultato tanto sudato! Salvare a questo punto in locale il file \"itanic_previsioni_sopravvivenza.csv\" e farne l'Upload seguendo le istruzioni nell'articolo allegato.\n",
    "\n",
    "Controlla come sei messo in Classifica Generale. Probabilmente, ti sarai collocato verso la metà alta dei Partecipanti totali. Questa Classifica viene aggiornata a rotazione ogni giorno, quindi contando che di solito si contano alcune decine di migliaia di Partecipanti, tutto sommato il risultato è tutt'altro che deludente!\n",
    "\n",
    "Ovviamente, sentiti libero di giocare con il Codice, di provare Reti Neurali con Architetture più o meno capaci di quella inclusa nell'esercizio, di provare diversi numeri di Epoch di Training e di dimensione del Minibatch di Apprendimento (nel nostro caso, 10 Record). Buon divertimento!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
